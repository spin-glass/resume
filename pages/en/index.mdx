import Downloads from "../../components/downloads";
import DateAndName from "../../components/DateAndName";

<DateAndName name="" />

# Resume

## Summary of Experience

Over the past six years, I have been involved in various projects as a data scientist. At my previous consulting firm, I acquired skills in leveraging data science for problem-solving. In my current role, I have been involved in the development of a machine learning system using Mynaportal data, handling everything from requirements definition to design. I have honed my system design skills, including security measures, by utilizing AWS. However, there is a slight gap between my current tasks and my interests, and I have limited opportunities to engage in machine learning and data analysis-related work. Moving forward, I aim to contribute in areas specialized in machine learning and data analysis, and I am currently studying system development utilizing LLM.

## Skills

- Machine Learning (DL/NLP/CV)
- Design, construction, and continuous improvement of machine learning systems
- Infrastructure (AWS/GCP/on-premise), including server-side and front-end web application development experience

## Development Environment / Languages / Libraries

- Cloud: AWS, GCP, Databricks
  - AWS: Sagemaker, ECR, Lambda, Athena, S3
  - GCP: Vertex AI, BigQuery, DataFlow, Cloud Run, Cloud Storage
- Languages: Python, R, Scala, Golang
- Tools: Pyspark, Pandas, scikit-learn, TensorFlow, PyTorch, MLFlow, Terraform

## Certifications

- Network Specialist
- Passed the Information Security Management Exam
- IELTS 6.0
- TOEIC 905

## Events

- [MLOps Study Session Speaker](https://mlops.connpass.com/event/218772/)
- Databricks Webinar Speaker

## Portfolio

[Resume](https://resume.spin-glass.dev/)

- Framework: Next.js (Nextra)
- Hosting: Vercel

[Movie Recommendation System using LangChain and LLM (in development)](https://github.com/spin-glass/langchain-movie-recommender)

- Pipeline:
  - Vertex AI Pipelines
  - LangChain
- LLM

## Work Experience

### Video Streaming Service Company - Machine Learning Engineer

#### Implementation of VOD Service Personalization Features

- **Period**: 2024/01 - Present
- **Role**: Requirements definition, design, development
- **Environment & Methods**:
  - GCP
    - Vertex AI Pipelines
    - Vertex AI Experiments
    - Vertex AI Workbench
    - DataProc
    - BigQuery
  - Natural Language Processing
    - Text embedding using BERT trained with Transfer Learning

- **Team Size**: 8
- **Details**:
  - **Point**: Responsible for the design and development from training to inference of the machine learning model.

#### Evaluation of Recommendation System Effectiveness

- **Period**: 2024/01 - Present
- **Role**: Requirements definition, analysis, reporting
- **Environment & Methods**:
  - Tools:
    - BigQuery
    - DataFlow
    - GCS
    - Tableau
  - Analysis Methods:
    - Chi-squared test
    - Bayesian inference

- **Team Size**: 5
- **Details**:
  - **Point**: Designing, analyzing, and reporting A/B tests to evaluate the effectiveness of the recommendation system.

### Healthcare Company (2023/06/01 - Present) - Data Innovation Lab

#### Development of an Insurance Company Screening System Using Mynaportal Data
- **Period**: 2023/06 - 2023/12
- **Role**: Requirements definition, design, development
- **Environment & Methods**: AWS
- **Team Size**: 12
- **Details**:
  - **Point**: Designing an insurance company screening system using Mynaportal data.
  - **Reason**: Utilizing Mynaportal data to approve insurance for people who are usually not screened, thereby improving profitability.
  - **Example**: Designed a secure data infrastructure and API using AWS. Mainly responsible for the machine learning system in a project involving three departments.

#### Development of a Reporting Function Using SageMaker Inference Pipeline
- **Period**: 2023/07 - 2023/12
- **Role**: Design, development, testing
- **Environment & Methods**: AWS SageMaker
- **Team Size**: 5
- **Details**:
  - **Point**: Developed a reporting function for pharmaceutical companies using SageMaker inference pipeline to report drug utilization numbers.
  - **Reason**: Automated the reporting process, which was previously manual, to help pharmaceutical companies make business decisions efficiently based on drug utilization numbers.
  - **Example**: Automated the entire flow from data collection to analysis and report generation using SageMaker. This system is expected to be expanded to handle other drugs in the future.

### Consulting Company (2022/09/01 - 2023/05/31)

#### M&A Data Analysis
- **Period**: 2023/01
- **Role**: Front-end development, algorithm development
- **Achievement**: Improved M&A success rate and efficiency of investment selection
- **Team Size**: 6
- **Environment & Methods**: Used Python and FastAPI, Elasticsearch, Logstash, Kibana for data organization, indexing, and visualization
- **Details**:
  - **Point**: The project resulted in improved M&A success rates and more efficient investment selection.
  - **Reason**: The project was conducted to efficiently evaluate the risks and returns of new investment targets.
  - **Example**: Organized, indexed, and visualized data using Elasticsearch, Logstash, and Kibana.

#### Calculation of Economic Impact of Used Car Dealers on Developing Countries
- **Period**: 2022/12 - 2022/01
- **Role**: Data engineer, data scientist
- **Achievement**: Confirmed the positive economic impact of used car distribution on developing countries
- **Team Size**: 8
- **Environment & Methods**: Data collection using UN Comtrade and World Bank Data, statistical causal inference using instrumental variables
- **Details**:
  - **Point**: Confirmed the positive impact of used car distribution on the economy of developing countries.
  - **Reason**: The project was necessary to evaluate the economic impact of used car distribution on developing countries.
  - **Example**: Analyzed the relationship between economic indicators and used car distribution using instrumental variables, selecting countries with similar economic scales as the target countries.

#### Financial Model Creation
- **Period**: 2022/12 - 2023/01
- **Role**: Front-end development
- **Achievement**: Enhanced precision in calculating corporate value and improved investment decision-making
- **Team Size**: 4
- **Environment & Methods**: Used Excel for discounted cash flow (DCF) method
- **Details**:
  - **Point**: Calculated corporate value with greater precision, leading to improved investment decision-making.
  - **Reason**: There was a need for a more precise calculation of corporate value.
  - **Example**: Calculated corporate value using Excel and the discounted cash flow (DCF) method.

### News Media Company (Contract Period: 3 years 2019/08/01 - 2022/07/31)

#### Design and Construction of Data Analysis Platform
- **Period**: 2019/10 - 2022/07
- **Role**: Data platform design and construction
- **Environment & Methods**: Databricks, AWS, GCP, Python, Scala, Spark, PySpark, Golang
- **Team Size**: 7
- **Overview and Achievement**:
  - Built a data analysis platform in collaboration with Databricks.
  - Enabled efficient data utilization and advanced analysis, and enhanced the personalization function of the news app "Nikkei Wave."
- **Details**:
  - Handled the design and construction of the platform with a team of seven, considering environmental constraints and goals.
  - Utilized AWS, GCP, Python, Scala, Spark, PySpark, and particularly managed MLOps centrally with Databricks.
  - This project significantly improved the efficiency of data analysis, model building, and deployment.

#### Development of Recommendation Algorithm
- **Period**: 2020/02 - 2022/07
- **Role**: Algorithm development
- **Environment & Methods**: Jupyter Notebook, TensorFlow, Pytorch, BERT, Collaborative Filtering
- **Achievement**:
  - Improved app CTR by approximately 5%
- **Details**:
  - Developed a new recommendation algorithm using BERT, TensorFlow, and Pytorch, overcoming the limitations of simple collaborative filtering.
  - This approach improved CTR by about 5%, significantly contributing to user engagement and corporate value.

#### Machine Learning System Development and Operation
- **Period**: 2020/06 - 2022/07
- **Role**: Architecture design, cloud development, backend development, frontend development
- **Environment & Methods**: AWS, Databricks, GCP, A/B Testing, CI/CD, Golang, Flutter
- **Details**:
  - Automated operations using AWS, GCP, and Databricks due to the limitations of manual operations and the need for effect validation.
  - Built a CI/CD pipeline and conducted A/B testing to quantitatively evaluate effects.
  - Also handled frontend and backend development using Golang and Flutter.
  - As a result, system quality and performance improved significantly.

### AI Startup (2019/02/01 - 2019/07/31)

- Analysis of Supermarket Purchase Trends

  - **Period**: 2019/04 - 2019/07
  - **Overview**: Worked as an in-house data scientist for a major trading company's DX division, consulting with various divisions and subsidiaries on AI utilization.
  - **Role**: Data scientist
  - **Environment & Methods**: R, Association Analysis
  - **Team Size**: 3

- Development of AI Learning Platform

  - **Period**: 2019/02 - 2019/07
  - **Overview**: Developed an educational AI platform.
  - **Role**: Backend development, frontend development
  - **Environment & Methods**: AWS, Bottle, Python, React
  - **Team Size**: 5

### AI Venture Company (2017/04/01 - 2019/01/31)

- Implementation of Image Modules for DL Library

  - **Period**: 2018/01 - 2019/01
  - **Overview**: Responsible for the image modules of a self-developed DL library.
  - **Role**: Machine Learning Engineer
  - **Environment & Methods**: SSG, VAE, VGG
  - **Team Size**: 5

- Development of Image Recognition System's FE/BE

  - **Period**: 2018/01 - 2019/01
  - **Overview**: Developed FE/BE for image recognition systems.
  - **Role**: Backend, frontend
  - **Environment & Methods**: Vue.js, Flask
  - **Team Size**: 5

- Development of Reinforcement Learning Platform for Plant Control

  - **Period**: 2018/11 - 2019/01
  - **Overview**: Responsible for the infrastructure of a plant control project using reinforcement learning.
  - **Role**: Data engineer, data platform design
  - **Environment & Methods**: Python, MQTT
  - **Team Size**: 3

- Fax Image Classification Model

  - **Period**: 2017/04 - 2018/12
  - **Overview**: Created a fax image classification model and integrated it into business systems.
  - **Role**: Data scientist
  - **Environment & Methods**: OpenCV, Python, VAE, VGG
  - **Team Size**: 2

### Web Development Company (2016/01/01 - 2017/03/31)

- Creation of In-house Portal Site

  - **Period**: 2016/12 - 2017/03
  - **Overview**: Handled the design and construction of service sites and was responsible for project management.
  - **Role**: Web Engineer
  - **Environment & Methods**: PHP
  - **Team Size**: 2

- Creation of Web Sites for Startups

  - **Period**: 2016/12 - 2017/03
  - **Overview**: Requirements definition, design, and construction of service sites.
  - **Role**: Web Engineer
  - **Environment & Methods**: Ruby on Rails
  - **Team Size**: 2

### SES Company (2014/05/01 - 2015/12/31)

- Operation and Maintenance of In-house Infrastructure

  - **Period**: 2014/03 - 2015/12
  - **Overview**: Operation and maintenance of in-house infrastructure.
  - **Role**: Operation and maintenance
  - **Environment & Methods**: Windows Server
  - **Team Size**: 15

- Creation of In-house Infrastructure Operation Design

  - **Period**: 2015/06 - 2015/12
  - **Overview**: Creation of operation design for in-house infrastructure.
  - **Role**: Design
  - **Environment & Methods**: ITIL
  - **Team Size**: 15

### Telecommunications Service Company (2013/04/01 - 2014/04/30)

- Design and Construction of In-house Service Site

  - **Period**: 2013/04 - 2014/04
  - **Overview**: Created an in-house service site using a LAMP stack.
  - **Role**: Design, construction
  - **Environment & Methods**: Apache, Linux, MySQL, PHP
  - **Team Size**: 2
