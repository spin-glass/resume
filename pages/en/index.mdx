import CurrentDate from "../../components/CurrentDate";

<CurrentDate/>

# Resume

## Summary of Experience

Over the past six years, I have been involved in various projects as a data scientist.At my previous consulting firm, I acquired skills in utilizing data science to solve problems.In my current position, I am involved in the development of machine learning systems using Mynaportal data, handling everything from requirements definition to design.I am honing my system design skills using AWS, including security measures.However, there is a slight gap between my interests and the tasks at my current job, and I have limited opportunities to engage in machine learning and data analysis. I am currently studying system development using LLMs, hoping to contribute in areas specializing in machine learning and data analysis in the future.

## Skills

- Machine Learning (DL/NLP/CV)
- Design, construction, and continuous improvement of machine learning systems
- Experience in developing web applications including infrastructure (AWS/GCP/on-premise), server-side, and front-end

## Development Environment/Languages/Libraries

- Cloud: AWS, GCP, Databricks
  - AWS: Sagemaker, ECR, Lambda, Athena, S3
  - GCP: Vertex AI, BigQuery, DataFlow, Cloud Run, Cloud Storage
- Languages: Python, R, Scala, Golang
- Tools: Pyspark, Pandas, scikit-learn, TensorFlow, PyTorch, MLFlow, Terraform

## Certifications

- Network Specialist
- Certified Information Security Specialist Examination Pass
- IELTS 6.0
- TOEIC 905

## Events

- [MLOps Study Group Speaker](https://mlops.connpass.com/event/218772/)
- Databricks Webinar Speaker

## Portfolio

[Resume](https://resume.spin-glass.dev/)

- Framework: Next.js (Nextra)
- Hosting: Vercel

[Movie Recommendation System using LangChain and LLM (Under Development)](https://github.com/spin-glass/langchain-movie-recommender)

- Pipeline
  - Vertex AI Pipelines
  - LangChain
- LLM

## Professional Experience

### Video Streaming Service Company Machine Learning Engineer

#### Implementation of personalization features for VOD services

- **Period**: 2024/01 - Present

- **Roles**: Requirements Definition, Design, Development

- **Environment and Methods**

- GCP
  - Vertex AI Pipelines
  - Vertex AI Experiments
  - Vertex AI Workbench
  - DataProc
  - BigQuery

- Natural Language Processing
  - Text embedding using BERT trained with Transfer Learning

- **Project Members**: 8

- **Details**:

- **Point**: I handle everything from learning to inference of the machine learning model alone.

#### Effect verification of the recommendation system

- **Period**: 2024/01 - Present

- **Roles**: Requirements Definition, Analysis, Reporting

- **Environment and Methods**
  - Tools
    - BigQuery
    - DataFlow
    - GCS
    - Tableau
  - Analysis Methods
    - Chi-square test
    - Bayesian Inference

- **Project Members**: 5

- **Details**:
  - **Point**: Designing, analyzing, and reporting A/B tests to verify the effectiveness of recommendation systems.

### Healthcare company (2023/06/01 - ) Data Innovation Lab

#### Construction of insurance company's screening system using Mynaportal data

- **Period**: 2023/06 - 2023/12
- **Role**: Requirement definition, design, and development
- **Environment/Method**: AWS
- **Project members**: 12
- **Details**:
  - **Point**: In this project, we are designing the screening system of the insurance company using Mynaportal data.
  - **Reason**: By utilizing Mynaportal data, we approve insurance even for people who are not normally screened, thereby improving profitability.
  - **Example**: Designed a secure data platform and API using AWS.In this project involving three departments, I am mainly responsible for the machine learning system.

#### Construction of reporting function using SageMaker inference pipeline

- **Period**: 2023/07 - 2023/12
- **Role**: Design, development, and testing
- **Environment/Method**: AWS SageMaker
- **Project members**: 5
- **Details**:
  - **Point**: Developed a reporting function for the number of medication usages for pharmaceutical companies using the AWS SageMaker inference pipeline.
  - **Reason**: Automated the manually developed report for pharmaceutical companies to make business decisions efficiently based on the number of medication usages.
  - **Example**: Automated the entire process from data collection to analysis and report generation utilizing SageMaker.It is expected that this system can be deployed when handling different medications in the future.

### Consulting company (2022/09/01 - 2023/05/31)

#### M&A data analysis

- **Period**: 2023/01
- **Role**: Front-end development, algorithm development
- **Outcomes**: Improved M&A success rate and selection efficiency of investment targets
- **Project members**: 6
- **Environment/Method**: Data arrangement, indexing, and visualization using Python, FastAPI, Elasticsearch, Logstash, Kibana
- **Details**:
  - **Point**: This project improved the M&A success rate and the efficiency of selecting investment targets.
  - **Reason**: The project was conducted to efficiently evaluate the risk and return of new investment targets.
  - **Example**: Used Elasticsearch, Logstash, and Kibana to organize, index, and visualize data.

#### Calculating the economic impact of used car dealers on developing countries they sell to

- **Period**: 2022/12 - 2022/01
- **Role**: Data engineer, data scientist
- **Outcomes**: Confirmation of the positive economic impact of used car distribution to developing countries
- **Project members**: 8
- **Environment/Method**: Data collection using UN Comtrade and World Bank Data, statistical causal inference using instrumental variable
- **Details**
  - **Point**: It was confirmed that the distribution of used cars to developing countries has a positive impact on the economy.
  - **Reason**: There was a need to evaluate the impact of used car distribution on the economies of developing countries.
  - **Example**: Analyzed the relationship between economic indicators and used car distribution using the instrumental variable method with countries similar in economic scale to the target countries.

#### Creation of financial models

- **Period**: 2022/12 - 2023/01
- **Role**: Front-end development
- **Outcomes**: Accurate calculation of corporate value and improvement of investment decisions
- **Project members**: 4
- **Environment/Method**: Discounted Cash Flow method (DCF) using Excel
- **Details**
  - **Point**: Accurately calculated corporate value, improving investment decisions.
  - **Reason**: Precise calculation of corporate value was needed.
  - **Example**: We calculated the corporate value using Excel and the discounted cash flow (DCF) method.

### News media company (Contract period: 3 years 2019/08/01 - 2022/07/31)

#### Design and construction of data analysis platform

- **Period**: 2019/10 - 2022/07
- **Role**: Data platform design and construction
- **Environment & Methods**: Databricks, AWS, GCP, Python, Scala, Spark, PySpark, Golang
- **Number of project members**: 7
- **Overview and Results**:
  - Built a data analysis platform in cooperation with Databricks.
  - Enabled efficient data utilization and advanced analysis, enhancing the personalization function of the news app Nikkei Wave.
- **Details**:
  - Responsible for the design and construction of the platform with a team of 7, considering environmental constraints and goals.
  - Utilized AWS, GCP, Python, Scala, Spark, PySpark, and specifically managed MLOps with Databricks.
  - This project significantly improved efficiency in data analysis, model construction, and deployment.

#### Development of recommendation algorithms

- **Period**: 2020/02 - 2022/07
- **Role**: Algorithm development
- **Environment & Methods**: Jupyter Notebook, TensorFlow, Pytorch, BERT, Collaborative Filtering
- **Results**:
  - Improved app CTR by approximately 5%
- **Details**:
  - Developed a new recommendation algorithm using BERT, TensorFlow, and Pytorch due to the limitations of simple collaborative filtering.
  - This approach improved CTR by about 5%, significantly contributing to user engagement and corporate value.

#### Machine learning system development and operation

- **Period**: 2020/06 - 2022/07
- **Role**: Architecture design, cloud development, backend development, frontend development
- **Environment & Methods**: AWS, Databricks, GCP, A/B Testing, CI/CD, Golang, Flutter
- **Details**:
  - Automated operations using AWS, GCP, and Databricks due to the limitations of manual operations and the need for effectiveness verification.
  - Constructed CI/CD pipeline and quantitatively evaluated effectiveness with A/B testing.
  - Also responsible for frontend and backend development using Golang and Flutter.
  - This significantly improved system quality and performance.

### AI startup company (2019/02/01 - 2019/07/31)

- Analysis of supermarket purchasing trends

  - Period: 2019/04 - 2019/07
  - Summary: Resident in the DX department of a major trading company, receiving consultations from various departments and subsidiaries on the use of AI
  - Role: Data Scientist
  - Environment & Methods: R, Association Analysis
  - Number of project members: 3

- Developed an AI learning platform

  - Period: 2019/02 - 2019/07
  - Summary: Development of a platform for AI education
  - Role: Backend development, frontend development
  - Environment & Methods: AWS, Bottle, Python, React
  - Number of project members: 5

### AI venture company (2017/04/01 - 2019/01/31)

- Implementation of image module papers for DL libraries

  - Period: 2018/01 - 2019/01
  - Summary: Responsible for the image module of a self-made DL library
  - Role: Machine learning engineer
  - Environment & Methods: SSG, VAE, VGG
  - Number of project members: 5

- FE/BE development for image recognition system development

  - Period: 2018/01 - 2019/01
  - Overview: FE/BE development for image recognition system
  - Role: BE, FE
  - Environment & Methods: Vue.js, Flask
  - Project team size: 5

- Reinforcement learning platform for plant control

  - Period: 2018/11 - 2019/01
  - Overview: Responsible for the infrastructure of plant control PJ using reinforcement learning
  - Role: Data Engineer, Data Infrastructure Design
  - Environment & Methods: Python, MQTT
  - Project team size: 3

- Fax image classification model

  - Period: 2017/04 - 2018/12
  - Overview: Created fax image classification model and integrated it into business systems
  - Role: Data Scientist
  - Environment & Methods: OpenCV, Python, VAE, VGG
  - Project team size: 2

### Web development company (2016/01/01 - 2017/03/31)

- Internal portal site creation

  - Period: 2016/12 - 2017/03
  - Overview: Responsible for service site design and construction as well as PM
  - Role: Web Engineer
  - Environment & Methods: PHP
  - Project team size: 2

- Web site creation for startups

  - Period: 2016/12 - 2017/03
  - Overview: Requirements definition, service site design and construction
  - Role: Web Engineer
  - Environment & Methods: Ruby on Rails
  - Project team size: 2

### SES company (2014/05/01 - 2015/12/31)

- Internal infrastructure operation and maintenance

  - Period: 2014/03 - 2015/12
  - Overview: Internal infrastructure operation and maintenance
  - Role: Operation and Maintenance
  - Environment & Methods: Windows Server
  - Project team size: 15

- Creation of internal infrastructure operation design

  - Period: 2015/06 - 2015/12
  - Overview: Creation of internal infrastructure operation design
  - Role: Design
  - Environment & Methods: ITIL
  - Project team size: 15

### Telecommunication services company (2013/04/01 - 2014/04/30)

- Design and construction of own service site

  - Period: 2013/04 - 2014/04
  - Overview: Created own service site using LAMP stack
  - Role: Design and Construction
  - Environment & Methods: Apache, Linux, MySQL, PHP
  - Project team size: 2
